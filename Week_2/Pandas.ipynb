{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9194fd66",
   "metadata": {},
   "source": [
    "# Pandas: Getting Started\n",
    "\n",
    "## Pandas Series\n",
    "\n",
    "Pandas series objects are used to store and manipulate single dimensional arrays of numbers. These are the basic data structures in pandas, which are a mix of lists and dictionaries, so you have indices of each data and string keys to define columns.\n",
    "\n",
    "Series on Pandas come from NumPy arrays, but Series has the values and indices expressed, not just intern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "769760af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98e0e45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Wiliam\n",
       "1     Molly\n",
       "2      Alex\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas stores our list in a Series by creating a new numpy array and sotring our values on it\n",
    "# This numpy aproach give to us various advantages, like more efficientcy when manipulating arrays\n",
    "students = ['Wiliam', 'Molly', 'Alex']\n",
    "\n",
    "pd.Series(students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19f8fcc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = [1, 2, 3]\n",
    "\n",
    "pd.Series(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaa3c8f",
   "metadata": {},
   "source": [
    "## None Values\n",
    "\n",
    "When creating a Series, Python verfies which element we are treating on the series. If it finds a None value, it will store it anyway on the numpy array and the type of the array will be of the underlyig array(without the None)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19ddb4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    William\n",
       "1       None\n",
       "2      Bruno\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = ['William', None, 'Bruno']\n",
    "\n",
    "pd.Series(testing)\n",
    "# try it: pd.Series(testing).dropna() -> 'drop all None values'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b317f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    2.0\n",
       "2    NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When recieving an array of integers or float numbers to creat a Series, Pandas verifies if the array has None objects.\n",
    "# If it has, pandas converts it to NaN (Not A Number) object and the rest of the numbers, dispite its integers or not, to\n",
    "# floating points\n",
    "numbers = [1, 2, None]\n",
    "\n",
    "pd.Series(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bf4c78",
   "metadata": {},
   "source": [
    "## Why None Values?\n",
    "\n",
    "For data scientists, None or NaN values are used to refference missing data. It's important to know how to clean these missing values from the data set if them do not improve any knowledge.\n",
    "\n",
    "## How to know if there is NaN values?\n",
    "\n",
    "Simple programming comparisons does not act like we wanted to NaN values. Because of that, it's important to use the ``isnan()`` functin which is present on the numpy library. It checks if a object is a NaN value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d213599e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b0df8b",
   "metadata": {},
   "source": [
    "## Creating Series from Dictionaries\n",
    "\n",
    "We've saw that when creating a list and passing it as argument to create a pandas series it will store for each element a key value which is a integer growing from 0 to len(list) - 1.\n",
    "\n",
    "But we can create a series from a dictionary as well. On that case, the key values will not be integers anymore, but using the key values from the dict instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89ca22aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Molly        Physics\n",
       "William         Math\n",
       "Andre      Chemistry\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students_grades = {'Molly': 'Physics',\n",
    "                   'William': 'Math',\n",
    "                   'Andre': 'Chemistry',\n",
    "                  }\n",
    "s = pd.Series(students_grades)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c08d771e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      (William, Sales)\n",
       "1    (Marcos, Vinicius)\n",
       "2         (João, Lucas)\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hThe dtype: object is not just for strings, is for any object type on `Python\n",
    "students_last_names = [('William', 'Sales'), ('Marcos', 'Vinicius'), ('João', 'Lucas')]\n",
    "\n",
    "pd.Series(students_last_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da221091",
   "metadata": {},
   "source": [
    "## Creating an arbitrary Series\n",
    "\n",
    "We can also pass as argument on the Series function which indexes we want to pick up from the list or dict. But, what happens if we say for the index argument a key which is not on our dict? Pandas will create a new field on the Series with that key and attribute to it a NaN value. If we exclude some key from the dict, pandas will simply not add it up on the Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5efde0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Molly      Physics\n",
       "William       Math\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Excluding the 'Andre' keyvalue\n",
    "pd.Series({'Molly': 'Physics', 'William': 'Math', 'Andre': 'Chemistry'}, index=['Molly', 'William'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "054d4839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Molly      Physics\n",
       "William       Math\n",
       "Sean           NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Argument index has a non exsiting keyvalue 'Sean'\n",
    "pd.Series({'Molly': 'Physics', 'William': 'Math', 'Andre': 'Chemistry'}, index=['Molly', 'William', 'Sean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fff4fe",
   "metadata": {},
   "source": [
    "## Querying Series\n",
    "\n",
    "There are a lot of ways for querying series from pandas. One of them is accessing the value on a series with it's index key, just the normal use of lists indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f7ef7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Molly        Physics\n",
       "William         Math\n",
       "Andre      Chemistry\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ec3f41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physics\n",
      "Physics\n",
      "Chemistry\n",
      "Chemistry\n"
     ]
    }
   ],
   "source": [
    "print(s['Molly'])\n",
    "print(s[0])\n",
    "print(s['Andre'])\n",
    "print(s[-1])\n",
    "# print(s['Mollya']) -> KeyError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87d099d",
   "metadata": {},
   "source": [
    "## The Power Of Vectorization\n",
    "\n",
    "Pandas Series can be treated as a iterable, which means that we can do all the operations that numpy has on our series too. Why just don't make a loop and iterate for each value of the series? We've discussed this before, numpy operations works with paralelism, which means that the library make various computations at the same time, speeding up the time of the algorithm really well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86b691e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4 ms ± 452 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "numbers = np.random.randint(0, 1000, 10000)\n",
    "ser = pd.Series(numbers)\n",
    "total = 0\n",
    "\n",
    "for number in ser:\n",
    "    total += number\n",
    "\n",
    "total/len(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12e851fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468 µs ± 58.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "numbers = np.random.randint(0, 1000, 10000)\n",
    "ser = pd.Series(numbers)\n",
    "\n",
    "total = np.sum(ser)\n",
    "total/len(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db774c3",
   "metadata": {},
   "source": [
    "## Merging Two Series Objects\n",
    "\n",
    "If we have two series which we want to merge into, we can use the ``append()`` function. This function returns a new series which is one concatenated with the other intead of modifying them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38e20d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Molly        Physics\n",
       "William         Math\n",
       "Andre      Chemistry\n",
       "Kelly        English\n",
       "Kelly        Physics\n",
       "Kelly           Math\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_kelly = pd.Series(['English', 'Physics', 'Math'], index=['Kelly', 'Kelly', 'Kelly'])\n",
    "new_series = s.append(student_kelly)\n",
    "\n",
    "new_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403f5b08",
   "metadata": {},
   "source": [
    "# Pandas Data Frames Objects\n",
    "\n",
    "Data Frames are the heart of pandas library. We can think about it as a two-dimension array which each column is labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25cba5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f32ed664",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_1 = {'Name': 'William', 'Course': 'Physics', 'Grade': 85}\n",
    "record_2 = {'Name': 'João', 'Course': 'Math', 'Grade': 95}\n",
    "record_3 = {'Name': 'Marcos', 'Course': 'Chemistry', 'Grade': 75}\n",
    "\n",
    "# record_1 = ['João', 'Almdeida'] -> try it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1abc38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Course</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>School 1</th>\n",
       "      <td>William</td>\n",
       "      <td>Physics</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>School 2</th>\n",
       "      <td>João</td>\n",
       "      <td>Math</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>School 3</th>\n",
       "      <td>Marcos</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name     Course  Grade\n",
       "School 1  William    Physics     85\n",
       "School 2     João       Math     95\n",
       "School 3   Marcos  Chemistry     75"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=[record_1, record_2, record_3], index=['School 1', 'School 2', 'School 3'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce563d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name      João\n",
       "Course    Math\n",
       "Grade       95\n",
       "Name: School 2, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['School 2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcc25853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.loc['School 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f348ed38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'William'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can merge the informations which we want to search by querying df[column][row]\n",
    "df['Name']['School 1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5528f323",
   "metadata": {},
   "source": [
    "## Droping values\n",
    "\n",
    "Pandas allow us to drop rows on data frames with the ``drop(row_index)`` function. It drops a row of the df according to the row_index argument. It will not affect out original df, but instead of it will create a copy with the row droped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e74287c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Course</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>School 2</th>\n",
       "      <td>João</td>\n",
       "      <td>Math</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>School 3</th>\n",
       "      <td>Marcos</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name     Course  Grade\n",
       "School 2    João       Math     95\n",
       "School 3  Marcos  Chemistry     75"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('School 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fad7e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Course</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>School 1</th>\n",
       "      <td>William</td>\n",
       "      <td>Physics</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>School 2</th>\n",
       "      <td>João</td>\n",
       "      <td>Math</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>School 3</th>\n",
       "      <td>Marcos</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name     Course  Grade\n",
       "School 1  William    Physics     85\n",
       "School 2     João       Math     95\n",
       "School 3   Marcos  Chemistry     75"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3eeb6e",
   "metadata": {},
   "source": [
    "In ``drop()`` function we can even set True to ``inplace`` argument which do not create a copy of the df, but instead manipulate the original itself. Other important argument is the ``axis``, which can be 0 to drop a row or ' to drop a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b76b2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f583a08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Course</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>School 1</th>\n",
       "      <td>William</td>\n",
       "      <td>Physics</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>School 2</th>\n",
       "      <td>João</td>\n",
       "      <td>Math</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name   Course  Grade\n",
       "School 1  William  Physics     85\n",
       "School 2     João     Math     95"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('School 3', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "408d55cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Course'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-646511fd0929>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Course'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4306\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4307\u001b[0m         \"\"\"\n\u001b[1;32m-> 4308\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4309\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4310\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4151\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4152\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4153\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4186\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4187\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4188\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4189\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5589\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5590\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5591\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5592\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5593\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Course'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df.drop('Course', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb18ee",
   "metadata": {},
   "source": [
    "## Querying Data Frames\n",
    "\n",
    "We need to understand boolean masks, which are one dimensional arrays of boolean values or two dimensional, like data frames.\n",
    "If we are querying a data frame, any cell with a True value will be admited and the others with False will not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8bc8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea92ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Admission_Predict.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2342b653",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(mapper=str.strip, axis='columns')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76f3bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(df.columns)\n",
    "cols = [x.lower().strip() for x in cols]\n",
    "df.columns = cols\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae72a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supose that we want to analyse only students with chance of admit greater than 0.7\n",
    "# So, we can create a series boolean mask with the column 'chance of admit'\n",
    "admit_mask = df['chance of admit'] > 0.7\n",
    "admit_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f6c1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So here we can do a list comprehension to store on a list all the values of admited series that are True\n",
    "# After that we can see that we have 235 students with chance of admit greater than 0.7\n",
    "admited = list([x for x in admit_mask if x == True])\n",
    "len(admited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ad601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[admit_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7e2475",
   "metadata": {},
   "source": [
    "Using ``df[mask_condition]`` is pretty much more common and fancy besides doing ``maks = series`` and ``df.where(mask).dropna()`` and drops the NaN values already."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ed7525",
   "metadata": {},
   "source": [
    "## Multiple Querying\n",
    "\n",
    "Everytime we gonna need to clean our data frame based on 2 or much more conditions for the cells inside of it. Because of this, we have to know how to multiple query a data frame.\n",
    "\n",
    "For that, is important to have all the column names on snake case using '_'. To do this, we are going to call a lambda function for each column of the data base.\n",
    "\n",
    "After that, we can call for the df the ``query()`` function, which is like: ``df.query('n-multiple conditions')``. For logical operators, we have: | -> 'or'; & -> 'and'; ! -> 'not';\n",
    "\n",
    "The query function returns a copy of the cleaned data frame and does not change the original one excepts we wanted it using the ``inplace=True`` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d658ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning data frame columns again to check double conditionals at querying\n",
    "cols = df.columns\n",
    "cols = cols.map(lambda x: x.replace(' ', '_') if isinstance(x, (str)) else x)\n",
    "df.columns = cols\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2627df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double querying using query() function -> '&': and; '|': or;\n",
    "df.query('chance_of_admit > 0.8 & research == 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08b2084",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed70e6e8",
   "metadata": {},
   "source": [
    "## Indexing Data Frames\n",
    "\n",
    "To Select just some of the columns we want ao analysea few of it we have to create a list of strings which each one is the name of the column that we want to analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcba2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['gre_score', 'toefl_score', 'chance_of_admit']\n",
    "df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e182f6",
   "metadata": {},
   "source": [
    "We can also define at the moment of reading the csv if we want to change the index column to some other existing doing index=position_column.\n",
    "\n",
    "Also, we can do a 'double indexing' using names of two different columns and the ``set_index()`` function.\n",
    "\n",
    "``\n",
    "    df_with_indices = df.set_index(['column_1', column_2])\n",
    "``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a266c955",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cdc0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('gre_score > 300 & chance_of_admit > 0.8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b3d221",
   "metadata": {},
   "source": [
    "## Handling with Missing Pandas\n",
    "\n",
    "When our data frame doesn't have some data and we can **predict** it from **other variables**, then we call the missing variable of **Data Missing at Random**. Otherwise if we could not predict this data we call it **Data Mising Completely at Random**.\n",
    "\n",
    "We can create a boolean numpy mask checking if each row of the df has NaN/NULL value using the ``isnan()``. If we want to drop all these NaN values we use the ``dropna()`` function.\n",
    "\n",
    "Or maybe if we are worried about filling the cells which has NaN values with some other arbitrary value we use the ``fillnan()`` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d02e0b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
